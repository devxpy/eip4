{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "SA_y1azbYrPY",
    "outputId": "dba9c663-f3fe-45a6-a9ba-135afc648382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyternotify extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyternotify\n"
     ]
    }
   ],
   "source": [
    "!pip install -q keras jupyternotify\n",
    "\n",
    "%load_ext jupyternotify\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Activation, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "qPexqpTnYrPe",
    "outputId": "3bd7bcbd-60d5-4a9c-a014-4aa7d198ccea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "mu0VAyMBYrPh",
    "outputId": "b71e7f98-f7db-4001-e411-9bb0809691dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "test_labels = np_utils.to_categorical(test_labels, 10)\n",
    "train_labels = np_utils.to_categorical(train_labels, 10)\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oFEoRxokYrPm",
    "outputId": "910cf539-4335-4004-bbd3-c775db07a852",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_575 (Conv2D)          (None, 26, 26, 24)        216       \n",
      "_________________________________________________________________\n",
      "batch_normalization_574 (Bat (None, 26, 26, 24)        96        \n",
      "_________________________________________________________________\n",
      "dropout_521 (Dropout)        (None, 26, 26, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_576 (Conv2D)          (None, 24, 24, 16)        3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_575 (Bat (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_522 (Dropout)        (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_577 (Conv2D)          (None, 22, 22, 16)        2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_576 (Bat (None, 22, 22, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_523 (Dropout)        (None, 22, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_112 (MaxPoolin (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_578 (Conv2D)          (None, 9, 9, 16)          2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_577 (Bat (None, 9, 9, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_524 (Dropout)        (None, 9, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_579 (Conv2D)          (None, 7, 7, 16)          2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_578 (Bat (None, 7, 7, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_525 (Dropout)        (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_580 (Conv2D)          (None, 5, 5, 10)          1440      \n",
      "_________________________________________________________________\n",
      "batch_normalization_579 (Bat (None, 5, 5, 10)          40        \n",
      "_________________________________________________________________\n",
      "dropout_526 (Dropout)        (None, 5, 5, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_581 (Conv2D)          (None, 3, 3, 10)          900       \n",
      "_________________________________________________________________\n",
      "batch_normalization_580 (Bat (None, 3, 3, 10)          40        \n",
      "_________________________________________________________________\n",
      "dropout_527 (Dropout)        (None, 3, 3, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_582 (Conv2D)          (None, 1, 1, 10)          900       \n",
      "_________________________________________________________________\n",
      "batch_normalization_581 (Bat (None, 1, 1, 10)          40        \n",
      "_________________________________________________________________\n",
      "dropout_528 (Dropout)        (None, 1, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_81 (Flatten)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 14,296\n",
      "Trainable params: 14,060\n",
      "Non-trainable params: 236\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
      "60000/60000 [==============================] - 45s 750us/step - loss: 0.5764 - acc: 0.8631 - val_loss: 0.1597 - val_acc: 0.9759\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.002.\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.2237 - acc: 0.9558 - val_loss: 0.0875 - val_acc: 0.9857\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0015.\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1766 - acc: 0.9649 - val_loss: 0.0816 - val_acc: 0.9872\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0012000000000000001.\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1480 - acc: 0.9700 - val_loss: 0.0594 - val_acc: 0.9879\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.001.\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.1347 - acc: 0.9723 - val_loss: 0.0520 - val_acc: 0.9912\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0008571428571428572.\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.1242 - acc: 0.9741 - val_loss: 0.0410 - val_acc: 0.9912\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.00075.\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.1114 - acc: 0.9767 - val_loss: 0.0381 - val_acc: 0.9922\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0006666666666666666.\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1062 - acc: 0.9778 - val_loss: 0.0334 - val_acc: 0.9922\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0006000000000000001.\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.1005 - acc: 0.9789 - val_loss: 0.0366 - val_acc: 0.9920\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0005454545454545455.\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.0938 - acc: 0.9798 - val_loss: 0.0303 - val_acc: 0.9928\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0005.\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0899 - acc: 0.9807 - val_loss: 0.0334 - val_acc: 0.9918\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.00046153846153846153.\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0863 - acc: 0.9810 - val_loss: 0.0314 - val_acc: 0.9926\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0004285714285714286.\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.0838 - acc: 0.9807 - val_loss: 0.0274 - val_acc: 0.9931\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0004.\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0810 - acc: 0.9811 - val_loss: 0.0258 - val_acc: 0.9946\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.000375.\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.0771 - acc: 0.9813 - val_loss: 0.0254 - val_acc: 0.9940\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.00035294117647058826.\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0767 - acc: 0.9817 - val_loss: 0.0235 - val_acc: 0.9941\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.0003333333333333333.\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0723 - acc: 0.9823 - val_loss: 0.0248 - val_acc: 0.9939\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00031578947368421053.\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0710 - acc: 0.9831 - val_loss: 0.0240 - val_acc: 0.9937\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.00030000000000000003.\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0679 - acc: 0.9842 - val_loss: 0.0241 - val_acc: 0.9937\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.00028571428571428574.\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0667 - acc: 0.9828 - val_loss: 0.0238 - val_acc: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f644030eb38>"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"1a6e6d0d-7d24-477b-afbb-62115f2787f7\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"1a6e6d0d-7d24-477b-afbb-62115f2787f7\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "\n",
    "model = Sequential()\n",
    "dropout = 0.05\n",
    "\n",
    "def add_conv2d( ksize, **kwargs):\n",
    "    model.add(Conv2D(ksize, 3, activation='relu', use_bias=False, **kwargs))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "add_conv2d(24, input_shape=train_images.shape[1:])\n",
    "add_conv2d(16)\n",
    "add_conv2d(16)\n",
    "model.add(MaxPooling2D(2))\n",
    "add_conv2d(16)\n",
    "add_conv2d(16)\n",
    "add_conv2d(10)\n",
    "add_conv2d(10)\n",
    "add_conv2d(10)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=3e-3), \n",
    "    # optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return 3e-3 / (1 + 0.5 * epoch)\n",
    "\n",
    "model.fit(\n",
    "    train_images, train_labels, \n",
    "    epochs=20,\n",
    "    validation_data=[test_images, test_labels],\n",
    "    verbose=1,\n",
    "    batch_size=256,\n",
    "    callbacks=[LearningRateScheduler(scheduler, verbose=1)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "joAgIrYDYrP-",
    "outputId": "c6b1c2b3-7141-4710-c6f6-7ac4b1691ba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 245us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.023790680991858243, 0.9939]"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "session_2 (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
